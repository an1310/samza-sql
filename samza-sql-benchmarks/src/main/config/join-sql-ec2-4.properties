
# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=join-sql-9

# YARN
yarn.package.path=http://mugo.cs.indiana.edu/${project.artifactId}-${pom.version}-dist.tar.gz
yarn.container.memory.mb=2048
yarn.container.count=4

# Task
task.class=org.apache.samza.sql.bench.JoinSQLTask
task.inputs=kafka.orders,kafka.products

task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.checkpoint.replication.factor=1

# Serializers
serializers.registry.orders.class=org.apache.samza.sql.bench.serde.CustomSqlAvroSerdeFactory
serializers.orders.schema=ORDERS
serializers.registry.int.class=org.apache.samza.sql.data.serializers.SqlIntegerSerdeFactory
serializers.registry.products.class=org.apache.samza.sql.bench.serde.CustomSqlAvroSerdeFactory
serializers.products.schema=PRODUCT
serializers.registry.join.class=org.apache.samza.sql.bench.serde.CustomSqlAvroSerdeFactory
serializers.join.schema=JOIN
serializers.registry.str.class=org.apache.samza.sql.bench.utils.StringSerdeFactory
serializers.registry.intmsgtuple.class=org.apache.samza.sql.bench.slidingwindow.IntermediateMessageTupleSerdeFactory

# Stores
stores.prel.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.prel.key.serde=str
stores.prel.msg.serde=intmsgtuple
stores.prel.changelog=kafka.productsstorelog
stores.prel.changelog.replication.factor=1

systems.kafka.streams.products.samza.bootstrap=true


# Kafka System
systems.kafka.samza.offset.default=oldest
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.streams.orders.samza.msg.serde=orders
systems.kafka.streams.orders.samza.key.serde=int
systems.kafka.streams.products.samza.msg.serde=products
systems.kafka.streams.products.samza.key.serde=int
systems.kafka.streams.joinsqloutput.samza.msg.serde=join
systems.kafka.streams.joinsqloutput.samza.key.serde=int
systems.kafka.consumer.zookeeper.connect=localhost:2181/
systems.kafka.producer.bootstrap.servers=localhost:9092

# Define a metrics reporter called "snapshot", which publishes metrics
# every 60 seconds.
metrics.reporters=snapshot
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory

# Tell the snapshot reporter to publish to a topic called "metrics"
# in the "kafka" system.
metrics.reporter.snapshot.stream=kafka.joinsqlmetrics

# Encode metrics data as JSON.
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory
systems.kafka.streams.joinsqlmetrics.samza.msg.serde=metrics
