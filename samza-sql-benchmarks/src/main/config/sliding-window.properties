
# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=sliding-window-1-1

# YARN
yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-dist.tar.gz
yarn.container.memory.mb=2048
yarn.container.count=1

# Task
task.class=org.apache.samza.sql.bench.SlidingWindowSQLStreamTask
task.inputs=kafka.orders

task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.checkpoint.replication.factor=1

# Serializers
serializers.registry.orders.class=org.apache.samza.sql.bench.serde.CustomSqlAvroSerdeFactory
serializers.orders.schema=ORDERS
serializers.registry.slidingout.class=org.apache.samza.sql.bench.serde.CustomSqlAvroSerdeFactory
serializers.slidingout.schema=SLIDINGWINDOW
serializers.registry.int.class=org.apache.samza.sql.data.serializers.SqlIntegerSerdeFactory
serializers.registry.long.class=org.apache.samza.sql.bench.utils.LongSerdeFactory
serializers.registry.str.class=org.apache.samza.sql.bench.utils.StringSerdeFactory
serializers.registry.partitionkey.class=org.apache.samza.sql.bench.slidingwindow.PartitionKeySerdeFactory
serializers.registry.aggregatestate.class=org.apache.samza.sql.bench.slidingwindow.AggregateStateSerdeFactory
serializers.registry.intmsgtuple.class=org.apache.samza.sql.bench.slidingwindow.IntermediateMessageTupleSerdeFactory
serializers.registry.tokey.class=org.apache.samza.sql.bench.slidingwindow.TimeAndOffsetKeySerdeFactory
serializers.registry.timekey.class=org.apache.samza.sql.bench.slidingwindow.TimeKeySerdeFactory
serializers.registry.timebasedaggstate.class=org.apache.samza.sql.bench.slidingwindow.TimeBasedSlidingWindowAggregatorStateSerdeFactory
serializers.registry.objarray.class=org.apache.samza.sql.bench.serde.OjectArraySerdeFactory

# Stores
stores.wnd-store-group-0.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.wnd-store-group-0.key.serde=timekey
stores.wnd-store-group-0.msg.serde=timebasedaggstate
stores.wnd-store-group-0.changelog=kafka.windowstorelog
stores.wnd-store-group-0.changelog.replication.factor=1

stores.msg-store-group-0.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.msg-store-group-0.key.serde=tokey
stores.msg-store-group-0.msg.serde=intmsgtuple
stores.msg-store-group-0.changelog=kafka.msgstorelog
stores.msg-store-group-0.changelog.replication.factor=1

stores.aggstatestore-group-0.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.aggstatestore-group-0.key.serde=partitionkey
stores.aggstatestore-group-0.msg.serde=objarray
stores.aggstatestore-group-0.changelog=kafka.aggstatestorelog
stores.aggstatestore-group-0.changelog.replication.factor=1

stores.group-state.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.group-state.key.serde=str
stores.group-state.msg.serde=long
stores.group-state.changelog=kafka.groupstatelog
stores.group-state.changelog.replication.factor=1


# Kafka System
systems.kafka.samza.offset.default=oldest
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.streams.orders.samza.msg.serde=orders
systems.kafka.streams.orders.samza.key.serde=int
systems.kafka.streams.slidingwindowsqloutput.samza.msg.serde=slidingout
systems.kafka.streams.slidingwindowsqloutput.samza.key.serde=int
systems.kafka.consumer.zookeeper.connect=localhost:2181/
systems.kafka.producer.bootstrap.servers=localhost:9092

# Define a metrics reporter called "snapshot", which publishes metrics
# every 60 seconds.
metrics.reporters=snapshot
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory

# Tell the snapshot reporter to publish to a topic called "metrics"
# in the "kafka" system
metrics.reporter.snapshot.stream=kafka.slidingwindowmetrics20

# Encode metrics data as JSON.
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory
systems.kafka.streams.slidingwindowmetrics20.samza.msg.serde=metrics

